# adapters/Jarvis/main.py
"""
Jarvis Adapter - Standalone FastAPI Server
"""

import json
import uvicorn
import requests
from datetime import datetime
sys.path.insert(0, "/DATA/AppData/MCP/Jarvis/Jarvis")
from shared_schemas import SequentialResponse, StepSchema
from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from typing import Optional

import sys
import os

# Path-Setup
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, PROJECT_ROOT)

from adapters.Jarvis.adapter import get_adapter
from core.bridge import get_bridge
from mcp.endpoint import router as mcp_router
from utils.logger import log_info, log_error, log_debug

# FastAPI App
app = FastAPI(
    title="Jarvis Adapter + MCP Hub + Sequential Thinking",
    description="Native Jarvis API → Core-Bridge + MCP Hub + Sequential Mode",
    version="2.1.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include Routers
app.include_router(mcp_router)

from adapters.Jarvis.maintenance_endpoints import router as maintenance_router
app.include_router(maintenance_router)

from adapters.Jarvis.persona_endpoints import router as persona_router
app.include_router(persona_router)


@app.get("/health")
async def health():
    """Health Check"""
    return {"status": "ok", "adapter": "jarvis", "version": "2.1.0"}


@app.post("/chat")
async def chat(request: Request):
    """Regular Chat Endpoint"""
    data = await request.json()
    
    adapter = get_adapter()
    bridge = get_bridge()
    
    core_request = adapter.transform_request(data)
    
    if core_request.stream:
        async def stream():
            async for chunk in bridge.stream_chat(core_request):
                response = adapter.transform_response(chunk)
                yield f"data: {json.dumps(response)}\n\n"
        return StreamingResponse(stream(), media_type="text/event-stream")
    else:
        response = await bridge.chat(core_request)
        return adapter.transform_response(response)


# ═══════════════════════════════════════════════════════════
# SEQUENTIAL THINKING ENDPOINTS (Task 2 - Phase 3)
# ═══════════════════════════════════════════════════════════

sequential_tasks = {}

@app.post("/chat/sequential")
async def chat_sequential(request: Request):
    """Sequential Thinking Mode Endpoint"""
    try:
        data = await request.json()
        message = data.get("message", "")
        
        if not message:
            raise HTTPException(status_code=400, detail="Message required")
        
        log_info(f"[Sequential] Starting: {message[:50]}...")
        
        # Call MCP Server
        # Use JSON-RPC endpoint (returns response directly, not wrapped!)
        mcp_url = "http://localhost:8001/"
        mcp_request = {
            "method": "tools/call",
            "params": {
                "name": "sequential_thinking",
                "arguments": {
                    "task_description": message
                }
            }
        }
        
        mcp_response = requests.post(mcp_url, json=mcp_request, timeout=5)
        
        if mcp_response.status_code != 200:
            raise HTTPException(status_code=502, detail="MCP Server error")
        
        mcp_data = mcp_response.json()
        # MCP Server now returns SequentialResponse with proper task_id and steps
        task_id = mcp_data.get("task_id", f"task_{int(datetime.now().timestamp() * 1000)}")
        
        sequential_tasks[task_id] = {
            "task_id": task_id,
            "message": message,
            "status": "running",
            "progress": mcp_data.get("progress", 0.0),
            "steps": mcp_data.get("steps", []),  # Properly populated from SequentialResponse!
            "started_at": mcp_data.get("started_at", datetime.now().isoformat())
        }
        
        log_info(f"[Sequential] Task {task_id} started with {len(mcp_data.get('steps', []))} steps")
        
        return {
            "success": True,
            "task_id": task_id,
            "steps_count": len(mcp_data.get("steps", []))
        }
        
    except Exception as e:
        log_error(f"[Sequential] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/sequential/status/{task_id}")
async def get_sequential_status(task_id: str):
    """Get Sequential Task Status"""
    if task_id not in sequential_tasks:
        raise HTTPException(status_code=404, detail="Task not found")
    
    task = sequential_tasks[task_id]
    steps = task.get("steps", [])
    
    if steps:
        verified = sum(1 for s in steps if s.get("status") == "verified")
        progress = verified / len(steps)
    else:
        progress = 0.0
    
    task["progress"] = progress
    if progress >= 1.0:
        task["status"] = "complete"
    
    return {
        "task_id": task_id,
        "status": task["status"],
        "progress": progress,
        "steps": steps
    }


@app.post("/sequential/stop/{task_id}")
async def stop_sequential_task(task_id: str):
    """Stop Sequential Task"""
    if task_id not in sequential_tasks:
        raise HTTPException(status_code=404, detail="Task not found")
    
    sequential_tasks[task_id]["status"] = "stopped"
    log_info(f"[Sequential] Task {task_id} stopped")
    
    return {"success": True, "task_id": task_id}


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
